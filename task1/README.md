# **Выводы по домашнему заданию: Regression + Inference**

В ходе работы с данными была проведена полноценная предобработка: удалось проверить наличие пропусков, аномалий и дубликатов, а затем очистить датасет от повторов и привести ключевые признаки (`mileage`, `engine`, `max_power`) к корректному числовому формату. Пропуски были заполнены медианами, а исследование распределений и корреляций помогло определить наиболее информативные факторы, влияющие на стоимость автомобиля. Такой предварительный анализ позволил сформировать основу для дальнейшего моделирования.

После подготовки данных были обучены первые модели на вещественных признаках. Линейная регрессия без масштабирования дала базовое качество, а после стандартизации стало заметно, что главным предиктором стоимости является характеристика мощности (`max_power`). Изучение поведения коэффициентов до и после скейлинга позволило лучше понять влияние отдельных признаков на итоговую цену.

Далее была исследована регуляризация. Lasso-регрессия при стандартных параметрах не дала улучшений и не занулила коэффициенты — вероятно, из-за того, что признаки достаточно значимые, а штраф оказался слабым. Даже подбор параметров через GridSearchCV не привёл к качественному скачку, хотя удалось получить небольшое повышение стабильности. ElasticNet также не продемонстрировало преимуществ перед обычной линейной регрессией, что подтвердило: задача лучше поддаётся L2-регуляризации, чем смешанной или L1.

Ситуация значительно изменилась после добавления категориальных признаков. Применение целевого кодирования для `name` и OneHotEncoding для остальных категорий сильно расширило признаковое пространство, но позволило модели работать с данными намного глубже. На таком расширенном наборе признаков особенно хорошо проявила себя Ridge-регрессия. После подбора оптимального значения `alpha` (≈1000) удалось добиться заметного скачка качества: R² на тестовой выборке вырос до **0.877**, что существенно превосходит показатели всех предыдущих моделей. Это подчёркивает важность категориальных данных в задаче ценообразования и эффективность L2-регуляризации для высокоразмерных пространств.

Сравнение моделей показало, что именно комбинация из добавления категорий, корректного масштабирования и регуляризации Ridge обеспечила наибольший прирост. Линейные модели без категориальных данных достигали лишь ~0.59 R², тогда как Ridge с OHE способен объяснять более 87% вариации цены. Это делает модель гораздо более применимой к производственным сценариям.

Тем не менее, не всё получилось идеально. Lasso не смогла занулить признаки — вероятно, признаковый состав оказался слишком информативным. ElasticNet также не дала выигрыша, что объясняется слабой выраженностью разреженной структуры в данных. При обработке категориальных признаков оставалась вероятность утечки данных при использовании target encoding, что требует аккуратности. Кроме того, существенный рост размерности после OHE создал предпосылки для замедления inference в реальных сервисах.

Разработанный ML-пайплайн получился достаточно удобным: этапы предобработки, обучения моделей, расчёта метрик и inference чётко разделены, что облегчает перенос системы в сервис. Визуализации помогают понять структуру данных и поведение моделей, хотя можно усилить блок анализа ошибок (например, добавить графики остатков или Q-Q-плоты). Среди ограничений стоит выделить зависимость Ridge от корректного масштабирования, что требует хранения и точного воспроизведения используемого scaler. Также расширившееся пространство признаков увеличивает вычислительную нагрузку.

Дальнейшее развитие системы может включать переход к более совершенным моделям, таким как CatBoost или XGBoost, которые обычно превосходят линейные методы на табличных данных и могут обеспечить R² выше 0.90. Полезным станет внедрение MLflow для отслеживания экспериментов, создание API на базе FastAPI для вывода сервиса в прод, а также интеграция Optuna для продвинутой оптимизации гиперпараметров. В части бизнес-метрик было выявлено, что Ridge значительно превосходит остальные модели, демонстрируя итоговый показатель 0.381, что на 55% выше результатов линейных и регуляризованных моделей без категориальных признаков.

В итоге работа показала, что качественная предобработка, использование категориальных признаков и корректная регуляризация способны существенно повысить точность моделей регрессии и сделать их пригодными для реальных производственных сценариев.
